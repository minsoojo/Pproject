# cleaning.py
from typing import Optional
import time

from .DBfetcher import fetch_rows_with_meta #file/html ë‚˜ëˆ ì£¼ëŠ” ì¹œêµ¬
from .FormClassifier import is_form #ì–‘ì‹ì¸ì§€ êµ¬ë¶„í•´ì£¼ëŠ” ì¹œêµ¬
from .htmlNotFormCleaner import clean_html_NotForm #ë¹„ì–‘ì‹ í´ë¦¬ë‹
from .FormCleaner import clean_form_file #ì–‘ì‹ í´ë¦¬ë‹
from connection.pipeline.run_cleaning import process_one_row
from connection.db.main_dao import fetch_rows_to_clean, update_clean_data   # â† ì—¬ê¸°ì„œë§Œ DBì— ì €ì¥
from concurrent.futures import ThreadPoolExecutor, as_completed
from .MeaningClassifier import classify_text

# 5) ì „ì²´ íŒŒì´í”„ë¼ì¸
def run_cleaning_pipeline(limit: Optional[int] = 1000):
    rows = fetch_rows_with_meta(limit=limit)

    for row in rows:
        row_id = row["id"]
        stype = row.get("source_type")

        if stype != "file":
            cleaned = process_one_row(row)
            cleaning_method = "html_gpt"
        else:
            if is_form(row):
                cleaned = clean_form_file(row)
                cleaning_method = "file_form_rule"
            else:
                cleaned = process_one_row(row)
                cleaning_method = "file_gpt"

        if isinstance(cleaned, str) and cleaned.strip():
            update_clean_data(row_id, cleaned)  # â† ì—¬ê¸°ì„œ TestMain.id ê¸°ì¤€ìœ¼ë¡œ ì €ì¥
            print(f"[OK] id={row_id} ({cleaning_method}) ì €ì¥ ì™„ë£Œ")
        else:
            print(f"[WARN] id={row_id} í´ë¦° ê²°ê³¼ê°€ ë¹„ì—ˆê±°ë‚˜ ë¬¸ìì—´ì´ ì•„ë‹™ë‹ˆë‹¤: {type(cleaned)}")

def process_and_store(row):
    """
    í•œ rowì— ëŒ€í•´:
    - source_type / ì–‘ì‹ ì—¬ë¶€ì— ë”°ë¼ ì•Œë§ì€ í´ë¦¬ë„ˆ í˜¸ì¶œ
    - ê²°ê³¼ë¥¼ TestMain.id ê¸°ì¤€ìœ¼ë¡œ update_clean_dataì— ì €ì¥
    """
    row_id = row["id"]
    stype = row.get("source_type")

    raw = row["raw_data"]

    if stype != "file":
        if classify_text(raw) == "trash":
            cleaned = None
            cleaning_method = "auto_trash_skip"
        else:
            cleaned = process_one_row(row)
            cleaning_method = "html_gpt"
    else:
        if is_form(row):
            cleaned = clean_form_file(row)
            cleaning_method = "file_form_rule"
        else:
            cleaned = process_one_row(row)
            cleaning_method = "file_gpt"

    if isinstance(cleaned, str) and cleaned.strip():
        update_clean_data(row_id, cleaned)
        print(f"[OK] id={row_id} ({cleaning_method}) ì €ì¥ ì™„ë£Œ")
        return True, row_id, cleaning_method
    else:
        msg = f"[WARN] id={row_id} í´ë¦° ê²°ê³¼ê°€ ë¹„ì—ˆê±°ë‚˜ ë¬¸ìì—´ì´ ì•„ë‹™ë‹ˆë‹¤: {type(cleaned)}"
        print(msg)
        return False, row_id, msg


# def run_cleaning_pipeline_parallel(limit: Optional[int] = 1000,
#                                    max_workers: int = 8):
#     """
#     fetch_rows_with_meta ë¡œ ê°€ì ¸ì˜¨ rowë“¤ì„
#     ThreadPoolExecutor ë¡œ ë³‘ë ¬ í´ë¦¬ë‹ + DB ì €ì¥.
#     """
#     rows = fetch_rows_with_meta(limit=limit)
#     total = len(rows)

#     if total == 0:
#         print("[INFO] í´ë¦¬ë‹í•  rowê°€ ì—†ìŠµë‹ˆë‹¤.")
#         return

#     print(f"[INFO] ë³‘ë ¬ í´ë¦¬ë‹ ì‹œì‘: ì´ {total}ê°œ, max_workers={max_workers}")

#     processed = 0
#     success_count = 0

#     start_time = time.time()

#     # ë³‘ë ¬ ì‹¤í–‰
#     with ThreadPoolExecutor(max_workers=max_workers) as executor:
#         futures = [executor.submit(process_and_store, row) for row in rows]

#         for future in as_completed(futures):
#             try:
#                 ok, row_id, info = future.result()
#                 processed += 1
#                 if ok:
#                     success_count += 1

#                 # ì§„í–‰ ìƒí™© ì¶œë ¥
#                 if processed % 50 == 0 or processed == total:
#                     elapsed = time.time() - start_time
#                     hours = elapsed / 3600 if elapsed > 0 else 0
#                     rate = processed / hours if hours > 0 else 0

#                     print(
#                         f"[parallel] ì§„í–‰ ìƒí™©: {processed}/{total}ê°œ ì²˜ë¦¬ "
#                         f"(ì„±ê³µ {success_count}ê°œ, ê²½ê³¼ {hours:.2f}ì‹œê°„, "
#                         f"ì‹œê°„ë‹¹ {rate:.1f}ê°œ)"
#                     )

#             except Exception as e:
#                 processed += 1
#                 msg = f"[parallel error] ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}"
#                 print(msg)

#     elapsed = time.time() - start_time
#     hours = elapsed / 3600 if elapsed > 0 else 0
#     rate = processed / hours if hours > 0 else 0

#     print(
#         f"\nğŸ‰ ë³‘ë ¬ í´ë¦¬ë‹ ì™„ë£Œ! ì´ {processed}/{total}ê°œ ì²˜ë¦¬ "
#         f"(ì„±ê³µ {success_count}ê°œ, ì´ {hours:.2f}ì‹œê°„, í‰ê·  {rate:.1f}ê°œ/ì‹œê°„)"
#     )
def run_cleaning_pipeline_resume(max_workers: int = 8):
    """
    DBì—ì„œ clean_data IS NULLì¸ rowë§Œ ê°€ì ¸ì™€ ë³‘ë ¬ ì²˜ë¦¬.
    ì¦‰, ì¤‘ë‹¨ëœ ìƒíƒœì—ì„œ ìë™ìœ¼ë¡œ ì´ì–´ì„œ ì‘ì—… ê°€ëŠ¥.
    limit ì œê±°ë¨.
    """
    rows = fetch_rows_with_meta()  # ì‚¬ì‹¤ìƒ ë¬´ì œí•œ zz

    total = len(rows)
    if total == 0:
        print("[INFO] ì²˜ë¦¬í•  ëŒ€ìƒì´ ì—†ìŠµë‹ˆë‹¤. ì´ë¯¸ ëª¨ë‘ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return

    print(f"[INFO] ì¬ì‹œì‘ ëª¨ë“œ: ì²˜ë¦¬ë˜ì§€ ì•Šì€ row {total}ê°œ ë°œê²¬. ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘.")

    start_time = time.time()
    success = 0

    from concurrent.futures import ThreadPoolExecutor, as_completed
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = [executor.submit(process_and_store, row) for row in rows]

        for idx, future in enumerate(as_completed(futures), start=1):
            try:
                ok, row_id, info = future.result()
                if ok:
                    success += 1
            except Exception as e:
                print(f"[ERROR] Future ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")

            if idx % 50 == 0 or idx == total:
                elapsed = (time.time() - start_time) / 3600
                rate = idx / elapsed if elapsed > 0 else 0
                print(f"[resume] {idx}/{total}ê°œ ì™„ë£Œ (ì†ë„ {rate:.1f}ê°œ/ì‹œê°„)")

    elapsed = (time.time() - start_time) / 3600
    print(f"\nğŸ‰ Resume ì™„ë£Œ! ì´ {success}/{total} ê°œ ì²˜ë¦¬ (ì´ {elapsed:.2f}ì‹œê°„)")


# # 6) ë””ë²„ê·¸ìš© íŒŒì´í”„ë¼ì¸
# def run_cleaning_pipeline_debug(limit: Optional[int] = 50):
#     print(f"[DEBUG] run_cleaning_pipeline_debug() ì‹œì‘, limit={limit}")
#     rows = fetch_rows_with_meta(limit=limit)

#     for idx, row in enumerate(rows, start=1):
#         stype = row.get("source_type")
#         doc_id = row.get("id")
#         title = row.get("title")
#         file_path = row.get("file_path")

#         print("\n" + "=" * 60)
#         print(f"[{idx}] id={doc_id} | source_type={stype}")
#         print(f"    title     = {title}")
#         print(f"    file_path = {file_path}")

#         # ì‹¤ì œ íŒŒì´í”„ë¼ì¸ íë¦„ê³¼ ë™ì¼í•˜ê²Œ ë¶„ê¸°í•˜ë©´ì„œ
#         # ì¤‘ê°„ì¤‘ê°„ ë¡œê·¸ë§Œ ë” ì°ì–´ì¤Œ
#         if stype != "file":
#             print("    â†’ HTML ë¬¸ì„œë¡œ íŒë‹¨: clean_html_NotForm() í˜¸ì¶œ")
#             cleaned = clean_html_NotForm(row)
#         else:
#             print("    â†’ íŒŒì¼ ë¬¸ì„œë¡œ íŒë‹¨")
#             form_flag = is_form(row)
#             print(f"    is_form() ê²°ê³¼: {form_flag}")

#             if form_flag:
#                 print("    â†’ ì–‘ì‹/ì‹ ì²­ì„œë¡œ ë¶„ë¥˜: clean_form_file() í˜¸ì¶œ")
#                 cleaned = clean_form_file(row)
#             else:
#                 print("    â†’ ì¼ë°˜ íŒŒì¼ë¡œ ë¶„ë¥˜: clean_html_NotForm() í˜¸ì¶œ")
#                 cleaned = clean_html_NotForm(row)

#         # cleaned ë‚´ìš© ê°„ë‹¨íˆ í™•ì¸
#         print(f"    í´ë¦¬ë‹ ê²°ê³¼ íƒ€ì…: {type(cleaned)}")

#         if isinstance(cleaned, str):
#             snippet = cleaned[:120].replace("\n", " ")
#             if len(cleaned) > 120:
#                 snippet += " ..."
#             print(f"    í´ë¦¬ë‹ ê²°ê³¼ ì• 120ì: {repr(snippet)}")
#         else:
#             print(f"    í´ë¦¬ë‹ ê²°ê³¼(ë¹„ë¬¸ìì—´): {repr(cleaned)}")

#     print("\n[DEBUG] run_cleaning_pipeline_debug() ì¢…ë£Œ")

# def run_cleaning_pipeline_debug_files(
#     file_limit: int = 50,
#     fetch_limit: int = 5000,
# ):
#     """
#     - DBì—ì„œ ìµœëŒ€ fetch_limitê°œë¥¼ ê°€ì ¸ì˜¨ ë’¤
#     - ê·¸ ì¤‘ì—ì„œ source_type == 'file' ì¸ rowë§Œ ê³¨ë¼
#       ìµœëŒ€ file_limitê°œë§Œ ë””ë²„ê¹…í•˜ëŠ” í•¨ìˆ˜
#     """
#     print(f"[DEBUG] run_cleaning_pipeline_debug_files() ì‹œì‘")
#     print(f"        DBì—ì„œ ìš°ì„  {fetch_limit}ê°œ fetch")
#     print(f"        ê·¸ ì¤‘ íŒŒì¼ ë¬¸ì„œ ìµœëŒ€ {file_limit}ê°œë§Œ ë””ë²„ê¹…\n")

#     rows = fetch_rows_with_meta(limit=fetch_limit)

#     file_count = 0
#     total_count = 0

#     for row in rows:
#         total_count += 1
#         stype = row.get("source_type")

#         # íŒŒì¼ë§Œ ë³´ê³  ì‹¶ìœ¼ë‹ˆê¹Œ, íŒŒì¼ ì•„ë‹ˆë©´ ìŠ¤í‚µ
#         if stype != "file":
#             continue

#         file_count += 1

#         doc_id = row.get("id")
#         title = row.get("title")
#         file_path = row.get("file_path")

#         print("\n" + "=" * 60)
#         print(f"[{file_count}] (ì „ì²´ {total_count}ë²ˆì§¸ row)")
#         print(f"    id        = {doc_id}")
#         print(f"    source_type = {stype}")
#         print(f"    title     = {title}")
#         print(f"    file_path = {file_path}")
#         print("    â†’ íŒŒì¼ ë¬¸ì„œë¡œ íŒë‹¨")

#         # ì–‘ì‹ ì—¬ë¶€
#         form_flag = is_form(row)
#         print(f"    is_form() ê²°ê³¼: {form_flag}")

#         if form_flag:
#             print("    â†’ ì–‘ì‹/ì‹ ì²­ì„œë¡œ ë¶„ë¥˜: clean_form_file() í˜¸ì¶œ")
#             cleaned = clean_form_file(row)
#         else:
#             print("    â†’ ì¼ë°˜ íŒŒì¼ë¡œ ë¶„ë¥˜: clean_html_NotForm() í˜¸ì¶œ")
#             cleaned = clean_html_NotForm(row)

#         # ê²°ê³¼ íƒ€ì…/ë‚´ìš© ì¼ë¶€ í™•ì¸
#         print(f"    í´ë¦¬ë‹ ê²°ê³¼ íƒ€ì…: {type(cleaned)}")

#         if isinstance(cleaned, str):
#             snippet = cleaned[:120].replace("\n", " ")
#             if len(cleaned) > 120:
#                 snippet += " ..."
#             print(f"    í´ë¦¬ë‹ ê²°ê³¼ ì• 120ì: {repr(snippet)}")
#         else:
#             print(f"    í´ë¦¬ë‹ ê²°ê³¼(ë¹„ë¬¸ìì—´): {repr(cleaned)}")

#         # ì›í•˜ëŠ” íŒŒì¼ ê°œìˆ˜ë§Œí¼ ë´¤ìœ¼ë©´ ì¢…ë£Œ
#         if file_count >= file_limit:
#             break

#     print(f"\n[DEBUG] run_cleaning_pipeline_debug_files() ì¢…ë£Œ")
#     print(f"    ì „ì²´ ì¡°íšŒ row ìˆ˜: {total_count}")
#     print(f"    ê·¸ ì¤‘ íŒŒì¼ ë¬¸ì„œ ìˆ˜: {file_count}")


if __name__ == "__main__":
    # ì§ë ¬ ë²„ì „
    # run_cleaning_pipeline(limit=1000)

    # ë³‘ë ¬ ë²„ì „ ì‚¬ìš©
    run_cleaning_pipeline_resume(max_workers=8)
