from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from pydantic import BaseModel, root_validator

import os
import re
import difflib
from pathlib import Path
from typing import Optional, List
# print("ğŸ“ FILE PATH:", os.path.abspath(__file__))
# key.env í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (ì—†ìœ¼ë©´ ë¬´ì‹œ)
_env_path = Path(__file__).resolve().parents[2] / "key.env"
try:
    from dotenv import load_dotenv  # type: ignore

    load_dotenv(_env_path)
except Exception:
    if _env_path.exists():
        for _line in _env_path.read_text(encoding="utf-8", errors="ignore").splitlines():
            _line = _line.strip()
            if not _line or _line.startswith("#"):
                continue
            if _line.startswith("export "):
                _line = _line[7:].lstrip()
            if "=" in _line:
                _k, _v = _line.split("=", 1)
                os.environ.setdefault(_k.strip(), _v.strip().strip("\"'"))
                
# from langChain_v3.RAGLLM.llm_runtime import get_llm
from langChain_v3.RAGLLM.rag_llm_for_server import answer_with_rag_for_server
from langChain_v3.RAGLLM.llm_service import generate_answer


# ===============================
# FastAPI
# ===============================
app = FastAPI(title="âˆ Assistant")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

RAG_ENABLED = os.getenv("RAG_ENABLED", "1").strip().lower() not in {"0", "false", "no", "off"}
DEBUG_RAG_ERRORS = os.getenv("DEBUG_RAG_ERRORS", "1").strip().lower() in {"1", "true", "yes", "on"}

# @app.on_event("startup")
# def startup():
#     print("[Server] Loading LLM once...")
#     get_llm()

# ===============================
# Request Model
# ===============================
class ChatRequest(BaseModel):
    message: str | None = None
    question: str | None = None

    @root_validator(pre=True)
    def ensure_message(cls, values):
        msg = values.get("message") or values.get("question")
        if not msg:
            raise ValueError("message is required")
        values["message"] = str(msg)
        return values

@app.get("/api/health")
def health():
    return {"status": "ok"}

@app.get("/api/chat")
def chat_info():
    return {"status": "ok", "detail": "Use POST /api/chat with a message."}

# ===============================
# ê·œì¹™ ê¸°ë°˜ ë¡œì§ (í”„ë¡ íŠ¸ ë¶„ ì½”ë“œ ìœ ì§€)
# ===============================

CHOSUNG_LIST = ["ã„±","ã„²","ã„´","ã„·","ã„¸","ã„¹","ã…","ã…‚","ã…ƒ","ã……","ã…†","ã…‡","ã…ˆ","ã…‰","ã…Š","ã…‹","ã…Œ","ã…","ã…"]

def get_chosung(text: str) -> str:
    result = []
    for ch in text:
        code = ord(ch)
        if 0xAC00 <= code <= 0xD7A3:
            idx = (code - 0xAC00) // 588
            result.append(CHOSUNG_LIST[idx])
    return "".join(result)

def is_chosung_input(text: str) -> bool:
    return bool(text) and all(ch in CHOSUNG_LIST for ch in text)


def correct_typo(msg: str, categories: List[str]) -> Optional[str]:
    matches = difflib.get_close_matches(msg, categories, n=1, cutoff=0.6)
    return matches[0] if matches else None

CATEGORY_RESPONSES = {
    "ìº í¼ìŠ¤ë§µ": {"reply": "ê°€ì²œëŒ€í•™êµ ìº í¼ìŠ¤ë§µ ì•ˆë‚´ì…ë‹ˆë‹¤.", "chosung": "ã…‹ã…ã……ã…"},
    "í•™ì‚¬ì¼ì •": {"reply": "í•™ì‚¬ì¼ì • ì•ˆë‚´ì…ë‹ˆë‹¤.", "chosung": "ã…ã……ã…‡ã…ˆ"},
    "ìˆ˜ê°•ì‹ ì²­": {"reply": "ìˆ˜ê°•ì‹ ì²­ ê´€ë ¨ ì•ˆë‚´ì…ë‹ˆë‹¤.", "chosung": "ã……ã„±ã……ã…Š"},
    "êµë‚´ì—°ë½ì²˜": {"reply": "êµë‚´ ì£¼ìš” ë¶€ì„œ ì—°ë½ì²˜ ì•ˆë‚´ì…ë‹ˆë‹¤.", "chosung": "ã„±ã„´ã…‡ã„¹ã…Š"},
    "ë“±ë¡ê¸ˆ": {"reply": "ë“±ë¡ê¸ˆ ë‚©ë¶€ ì•ˆë‚´ì…ë‹ˆë‹¤.", "chosung": "ã„·ã„¹ã„±"},
    "í¸ì˜ì‹œì„¤": {"reply": "í¸ì˜ì‹œì„¤ ì•ˆë‚´ì…ë‹ˆë‹¤.", "chosung": "ã…ã…‡ã……ã……"},
    "ë„ì„œê´€": {"reply": "ë„ì„œê´€ ì´ìš© ì•ˆë‚´ì…ë‹ˆë‹¤.", "chosung": "ã„·ã……ã„±"},
}

# ===============================
# í†µí•© Chat API
# ===============================
# @app.post("/api/chat")
# def chat(req: ChatRequest):
#     msg = re.sub(r"[^\wê°€-í£]", "", req.message.strip())
#     categories = list(CATEGORY_RESPONSES.keys())

#     # 1) ì •í™•/í¬í•¨ ë§¤ì¹­
#     for category, data in CATEGORY_RESPONSES.items():
#         if category in msg:
#             return {
#                 "type": "category",
#                 "category": category,
#                 "reply": data["reply"],
#                 "suggestions": [
#                     f"{category} ìƒì„¸ ì•ˆë‚´",
#                     f"{category} ì´ìš© ë°©ë²•",
#                 ],
#             }

#     # 2) ì´ˆì„±
#     user_chosung = msg if is_chosung_input(msg) else get_chosung(msg)
#     for category, data in CATEGORY_RESPONSES.items():
#         if user_chosung == data["chosung"]:
#             return {
#                 "type": "category",
#                 "category": category,
#                 "reply": data["reply"],
#                 "suggestions": [
#                     f"{category} ìƒì„¸ ì•ˆë‚´",
#                     f"{category} ì´ìš© ë°©ë²•",
#                 ],
#             }

#     # 3) ì˜¤íƒ€ ë³´ì •
#     corrected = correct_typo(msg, categories)
#     if corrected:
#         data = CATEGORY_RESPONSES[corrected]
#         return {
#             "type": "category",
#             "category": corrected,
#             "reply": data["reply"],
#         }

#     # 4) ğŸ”¥ fallback â†’ RAG
#     if not RAG_ENABLED:
#         answer = generate_answer(
#             system_prompt=(
#                 "ë‹¹ì‹ ì€ ê°€ì²œëŒ€í•™êµ AI ì±—ë´‡ì…ë‹ˆë‹¤.\n"
#                 "í•œêµ­ì–´ ì¡´ëŒ“ë§ë¡œ 1~3ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”."
#             ),
#             user_prompt=req.message,
#         )
#         return {"type": "llm", "reply": answer, "used_rag": False}

#     try:
#         rag_result = answer_with_rag_for_server(req.message)
#         # print(rag_result.get("contexts", []))
#         return {
#             "type": "rag",
#             "reply": rag_result["answer"],
#             "contexts": rag_result.get("contexts", []),
#             "used_rag": rag_result.get("used_rag", True),
#         }
#     except Exception as e:
#         answer = generate_answer(
#             system_prompt=(
#                 "ë‹¹ì‹ ì€ ê°€ì²œëŒ€í•™êµ AI ì±—ë´‡ì…ë‹ˆë‹¤.\n"
#                 "í•œêµ­ì–´ ì¡´ëŒ“ë§ë¡œ 1~3ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”."
#             ),
#             user_prompt=req.message,
#         )
#         resp = {"type": "llm", "reply": answer, "used_rag": False}
#         if DEBUG_RAG_ERRORS:
#             resp["rag_error"] = repr(e)
#         return resp
@app.post("/api/chat")
async def chat(req: ChatRequest):
    msg = re.sub(r"[^\wê°€-í£]", "", req.message.strip())
    categories = list(CATEGORY_RESPONSES.keys())

    # 1) ì¹´í…Œê³ ë¦¬ ë§¤ì¹­
    for category, data in CATEGORY_RESPONSES.items():
        if category in msg:
            return {
                "type": "category",
                "category": category,
                "reply": data["reply"],
                "suggestions": [
                    f"{category} ìƒì„¸ ì•ˆë‚´",
                    f"{category} ì´ìš© ë°©ë²•",
                ],
            }

    # 2) ì´ˆì„±
    user_chosung = msg if is_chosung_input(msg) else get_chosung(msg)
    for category, data in CATEGORY_RESPONSES.items():
        if user_chosung == data["chosung"]:
            return {
                "type": "category",
                "category": category,
                "reply": data["reply"],
                "suggestions": [
                    f"{category} ìƒì„¸ ì•ˆë‚´",
                    f"{category} ì´ìš© ë°©ë²•",
                ],
            }

    # 3) ì˜¤íƒ€ ë³´ì •
    corrected = correct_typo(msg, categories)
    if corrected:
        data = CATEGORY_RESPONSES[corrected]
        return {
            "type": "category",
            "category": corrected,
            "reply": data["reply"],
        }

    # 4) fallback
    if not RAG_ENABLED:
        answer = generate_answer(
            system_prompt=(
                "ë‹¹ì‹ ì€ ê°€ì²œëŒ€í•™êµ AI ì±—ë´‡ì…ë‹ˆë‹¤.\n"
                "í•œêµ­ì–´ ì¡´ëŒ“ë§ë¡œ 1~3ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”."
            ),
            user_prompt=req.message,
        )
        return {"type": "llm", "reply": answer, "used_rag": False}

    try:
        rag_result = answer_with_rag_for_server(
            question=req.message,
            k=5
            )
        return {
            "type": "rag",
            "reply": rag_result["answer"],
            "contexts": rag_result.get("contexts", []),
            "used_rag": rag_result.get("used_rag", True),
        }

    except Exception as e:
        answer = generate_answer(
            system_prompt=(
                "ë‹¹ì‹ ì€ ê°€ì²œëŒ€í•™êµ AI ì±—ë´‡ì…ë‹ˆë‹¤.\n"
                "í•œêµ­ì–´ ì¡´ëŒ“ë§ë¡œ 1~3ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”."
            ),
            user_prompt=req.message,
        )
        resp = {"type": "llm", "reply": answer, "used_rag": False}
        if DEBUG_RAG_ERRORS:
            resp["rag_error"] = repr(e)
        return resp
# ===============================
# React dist ì„œë¹™
# ===============================
BASE_DIR = Path(__file__).resolve().parent.parent.parent
# FRONTEND_DIR = BASE_DIR / "muhanchatbot" / "dist" / "public"
FRONTEND_DIR = BASE_DIR / "muhanchatbot-main" / "dist" / "public"
# app.mount("/", StaticFiles(directory="muhanchatbot/dist", html=True), name="frontend")
app.mount(
    "/",
    StaticFiles(directory=FRONTEND_DIR, html=True),
    name="frontend",
)
# app.mount("/ui", StaticFiles(directory=FRONTEND_DIR, html=True), name="frontend")
